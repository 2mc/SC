{\rtf1\mac\ansicpg10000\cocoartf824\cocoasubrtf410
{\fonttbl\f0\fswiss\fcharset77 Helvetica-Bold;\f1\fswiss\fcharset77 Helvetica;\f2\fnil\fcharset77 Monaco;
}
{\colortbl;\red255\green255\blue255;\red22\green61\blue211;\red191\green0\blue0;\red0\green0\blue0;
\red191\green0\blue0;\red0\green0\blue191;\red0\green115\blue0;}
\deftab560
\pard\pardeftab560\ql\qnatural

\f0\b\fs36 \cf0 LGDSarsa			
\fs24 linear gradient descent sarsa(lambda) reinforcement learning
\fs36 	
\f1\b0\fs24 \
\

\f0\b Inherits from: {\field{\*\fldinst{HYPERLINK "file:///Volumes/data/SuperCollider/SuperCollider3/build/Help/Core/Object.html"}}{\fldrslt \cf2 Object}}
\f1\b0 \

\f2\fs18 \

\f1\fs24 Reinforcement learning for large state-action spaces in the case of tile coding with binary features, epsilon-greedy policy and accumulating or replacing traces. Guaranteed convergence; for less linear behaviour, need to add 'interaction' features that combine multiple feature dimensions. \
\
Various functions must be provided to the class to customise it to your particular purpose. \
\
\

\f0\b\fs28 Creation / Class Methods
\f1\b0 \
\pard\pardeftab560\li1140\fi-1140\ql\qnatural

\f2\fs18 \cf0 \

\f0\b\fs24 	*new(numfeatures=10, actions, stateactiontofeature, rewardfunc, epsilon=0.1, alpha=0.1, gamma=0.9, lambda=0.9, accum=false)
\f1\b0 \

\f0\b \
		numfeatures 
\f1\b0 - number of binary features, required for setting up learning parameters 
\f0\b 	
\f1\b0 \
\pard\pardeftab560\li1700\fi-1700\ql\qnatural
\cf0 		
\f0\b actions 
\f1\b0 - array of allowed actions \
		
\f0\b stateactiontofeature 
\f1\b0  - Function mapping from arg state, action to a set of indices of those binary features which are implicated\
		
\f0\b reward 
\f1\b0  - Function mapping from arg action, newstate to a reward signal\
\pard\pardeftab560\ql\qnatural
\cf0 \
\pard\pardeftab560\li1140\fi-1140\ql\qnatural

\f0\b\fs28 \cf0 Examples
\f1\b0 \
\pard\pardeftab560\ql\qnatural

\f2\fs18 \cf0 \
\cf3 //PROBLEMATIC: \cf4 \
\cf3 //all examples seem biased to view action as a prediction, which is a difficult procedure...\cf4 \
\cf0 \
\cf3 //can musical space be a maze which is run and explored by the musical algorithm? \cf4 \
\cf3 //rewards for cadences etc? \cf4 \
\
\cf3 //assuming some final goal; succession of states is teleological; what are final musical objectives? \
//sequence of episodes; one phrase = episode, then have objective function to calculate value of that? \
\
//Does RL assume you want to get to a particular end state? No, just that approximate perfect Q, value function over state-action pairs\
\cf0 \
\
\
\
\pard\pardeftab560\ql\qnatural
\cf5 // state is 0-11, action is 0-11, binary features are simple; \cf0 \
\cf5 //one characteristic function for each possible value of state and action, so a total of 24 features \cf0 \
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 n = \cf6 LGDSarsa\cf0 (24,(0..11),\{\cf6 |s,a|\cf0  [s,a+12]\},\{\cf6 |a,s2|\cf0  if(a==s2,1,0)\}); \
\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf5 //given a new state, train up!\cf0 \
n.train(12.rand);\
\
\cf5 //it won't be able to predict randomness, of course. \cf0 \
\
\
(\
\cf6 var\cf0  sequence; \
\
\cf5 //essentially, giving it the answer, but this is a test to make sure it can learn something!\cf0 \
n = \cf6 LGDSarsa\cf0 (12,(0..11),\{\cf6 |s,a|\cf0  if((s+1)%12==a,[a],[])\},\{\cf6 |a,s2|\cf0  if(a==s2,1,0)\}); \
\
\cf5 //init state and action\cf0 \
n.s= 0;\
n.a= 0;\
\
\cf5 //source of state\cf0 \
sequence= \cf6 Pseq\cf0 ((0..11),\cf6 inf\cf0 ).asStream;\
\
100.do \{\cf6 var\cf0  nextstate, prediction; prediction= n.a; nextstate =sequence.next;  [\cf7 \\statenow\cf0 , nextstate, \cf7 \\prediction\cf0 , prediction].postln; n.train(nextstate)\};\
)\
\
n.theta\
n.e\
n.a2 \cf5 //next prediction\cf0 \
\
n.distribution(9); \cf5 //shows probability distribution from state 6 to next action\cf0 \
\
\
\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab560\ql\qnatural\pardirnatural
\cf5 //hidden transition generator, want to learn to predict it\
//now, obvious monte carlo method is much better here (thugh see my discrete state space results from the other file where RL outperforms it!), but curious about RL in this context \cf0 \
(\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab560\ql\qnatural\pardirnatural
\cf6 var\cf0  nextp, last, tmp, sequence, tmp2, tmp3; \
\cf6 var\cf0  laststate; \
\
m=\cf6 Array\cf0 .fill(144,\{0\}); \cf5 //monte carlo estimate; add up time of each transition\cf0 \
\
p= [ 0.047873594026637, 0.080826749857666, 0.047941249907149, 0.077194165390558, 0.081215439130136, 0.010252900965678, 0.046444197046431, 0.020089243258251, 0.073700618700493, 0.17163013349925, 0.12546371161048, 0.21736799660726, 0.078534462518124, 0.022533184840552, 0.064198699245631, 0.074374510048125, 0.088126562920523, 0.18726247023756, 0.00062892714572889, 0.014489263858497, 0.13721499734884, 0.17094938595627, 0.15133411041267, 0.010353425467481, 0.19111378610518, 0.014393017469096, 0.0037559331238541, 0.019074178375717, 0.16944643368592, 0.02020845034634, 0.0095455981117081, 0.16098607237158, 0.17590293388939, 0.1880851047306, 0.043633839067708, 0.0038546527229134, 0.0081567735414689, 0.22690344224671, 0.067743472620877, 0.31076962725616, 0.0084237407988129, 0.011358108969371, 0.080711913125772, 0.065109429849837, 0.00055617960502401, 0.066195549184565, 0.11475385870385, 0.039317904097556, 0.0060956765907998, 0.023426013859502, 0.046843772017401, 0.067179787769452, 0.034335937191582, 0.10957279228074, 0.029244296399311, 0.22639253418859, 0.14438692079677, 0.22066140123107, 0.00023416852354727, 0.091626699151229, 0.091933253239214, 0.091269157324387, 0.071898821863552, 0.040237280775343, 0.13225676828844, 0.0056224254692286, 0.031726723718983, 0.12915019406708, 0.13641323819981, 0.017130871664528, 0.013707817216658, 0.23865344817278, 0.076312663528366, 0.059262072972401, 0.02598413498885, 0.10410380686335, 0.19017654291831, 0.051217868910339, 0.024773988438023, 0.13696451695503, 0.070062275674588, 0.11358858763476, 0.063837489483962, 0.083716051632018, 0.025471293095253, 0.21257018875625, 0.039804675624999, 0.24661149211191, 0.054061008342468, 0.036708514022697, 0.023420258038583, 0.14986021390175, 0.014181127664185, 0.0099482889621581, 0.023017772199195, 0.16434516728055, 0.082387490785987, 0.039942485347338, 0.22073989653689, 0.017213645836245, 0.11394330239387, 0.1034484413001, 0.064152578780638, 0.0065874717451339, 0.048474126874629, 0.22627620432266, 0.020455668651227, 0.056378687425287, 0.021271296445112, 0.061681184500447, 0.02530307598093, 0.072134796078538, 0.017132372011911, 0.025080142367054, 0.15974665945312, 0.13983710082588, 0.19977101966997, 0.18358013842321, 0.030664291826161, 0.063797922417658, 0.013497094100277, 0.027104913124381, 0.029640856971333, 0.12349064070504, 0.18686140647733, 0.049980116290342, 0.13083701270858, 0.040145869844021, 0.16653194223897, 0.020609360359758, 0.1990519069099, 0.012248880270065, 0.054058801676878, 0.012355204001767, 0.067125199807544, 0.028411207887273, 0.27287333873003, 0.0065108269452922, 0.18297882367653, 0.014016608594546, 0.085673956115894, 0.032365353031109, 0.21630335103269, 0.027327328500458 ]; \
\
last=0;\
laststate=0;\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab560\ql\qnatural\pardirnatural
\cf5 //function for generating samples of this\cf0 \
nextp= \{tmp= last;  last= p[(tmp*12)..(tmp*12+11)]; last= (0..11).wchoose(last); tmp;\};\
\
\pard\pardeftab560\ql\qnatural
\cf5 // state is 0-11, action is 0-11 //only realistic strategy is a model that can cope with all 144 numbers in the hidden model\cf0 \
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 n = \cf6 LGDSarsa\cf0 (144,(0..11),\{\cf6 |s,a|\cf0  [12*s+a]\},\{\cf6 |a,s2|\cf0  if(a==s2,1,0)\}, 0.1, 0.05,0.1,0.9, \cf6 true\cf0 ); \
\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf5 //init state and action\cf0 \
n.s= 0;\
n.a= 0;\
\
\cf5 //source of state\cf0 \
sequence= \cf6 Pfunc\cf0 (nextp,\cf6 inf\cf0 ).asStream;\
\
10000.do \{\cf6 |i|\cf0  \cf6 var\cf0  nextstate, prediction; \
\
prediction= n.a; \
nextstate =sequence.next;  \
m[laststate*12+nextstate] = m[laststate*12+nextstate] + 1; \cf5 //just accumulate evidence\cf0 \
\
\cf5 //n.epsilon = max(0.01,0.1 - (0.1*(i/10000))); //annealing\cf0 \
\
if(i%10==0,\{\
[\cf7 \\statenow\cf0 , nextstate, \cf7 \\prediction\cf0 , prediction].postln;\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab560\ql\qnatural\pardirnatural
\cf0 tmp2=0.0; tmp3=0.0;\
\
12.do \{\cf6 |j|\cf0  tmp2= tmp2 + ((n.distribution(j))-(p[(j*12)..(j*12+11)])).squared.sum; \};\
12.do \{\cf6 |j|\cf0  tmp3= tmp3 + (((m[(j*12)..(j*12+11)]).normalizeSum)-(p[(j*12)..(j*12+11)])).squared.sum; \};\
\
[\cf7 \\error\cf0 , tmp2, \cf7 \\monte\cf0 , tmp3].postln;\
\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 \});\
\
n.train(nextstate);\
laststate=nextstate; \
\};\
)\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab560\ql\qnatural\pardirnatural
\cf0 \
\
\
(\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 n.distribution(0).plot;\
p[0..11].plot;\
m[0..11].plot;\
\
((n.distribution(0))-(p[0..11])).squared.sum\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab560\ql\qnatural\pardirnatural
\cf0 )\
\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 \
\
\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf5 //OK, MIDI note and timing prediction here we come!\cf0 \
\
\cf5 //ignore noteoffs for now, just onset time and pitch, predicted with respect to last N notes\cf0 \
\
\cf6 MIDIIn\cf0 .connect;\
\
\
\cf5 //create multiple active LGDSarsa objects and keep swapping to best recent performance; well off pace ones can die and be replaced by new ones\
//or if way off after 100 notes, allow epsilon to increase for 100, then fall back, etc\cf0 \
\cf5 //try just pitch on its own first, no timing for now, even then may be independent rather than joint\cf0 \
(\
\cf6 var\cf0  lastiois, lastnotes, lastintervals; \
\cf6 var\cf0  rl, now, last, ioi, lastnote;\
\
\cf5 //n=4;\cf0 \
\
last=\cf6 Main\cf0 .elapsedTime;\
lastnote=48;\
\
lastiois= \cf6 List\cf0 [0.5,0.5,0.5,0.5];\
lastnotes= \cf6 List\cf0 [60,60,60,60];\
lastintervals= \cf6 List\cf0 [0,0,0,0];\
\
\
\pard\pardeftab560\ql\qnatural
\cf5 // state is note now 0-23 plus last 3 intervals each -24 to 24 plus note predicted as action 0-23  =4*48\cf0 \
\cf5 //state= [note now, last 3 intervals] action=note predicted\cf0 \
\cf5 //feature as characteristic function for each of these first; later add interactions s[1]-s[2] etc\cf0 \
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 rl = \cf6 LGDSarsa\cf0 (192,(0..23),\{\cf6 |s,a|\cf0  [s[0], s[1]+24,s[2]+72,s[3]+120,a+168]\},\{\cf6 |a,s2|\cf0  if(a==(s2[0]),1,0)\}, 0.1, 0.05,0.1,0.9, \cf6 true\cf0 ); \
\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf5 //init state and action\cf0 \
rl.s= [0,0,0,0];\
rl.a= 0;\
\
\cf6 MIDIIn\cf0 .noteOn = \{ \cf6 arg\cf0  src, chan, num, vel; 	\
	\cf6 var\cf0  state;\
	\
	now=\cf6 Main\cf0 .elapsedTime;\
	\
	\cf5 //2 octave range\cf0 \
	if ((num>47) && (num<72), \{\
	\
	ioi= now-last;\
	\
	lastiois.addFirst(ioi); \
	lastiois.pop; \cf5 //remove most distant\cf0 \
	\
	lastnotes.addFirst(num-48);  \
	lastnotes.pop; \cf5 //remove most distant\cf0 \
	\
	lastintervals.addFirst(num-lastnote);  \
	lastintervals.pop; \cf5 //remove most distant\cf0 \
	\
	lastnote = num;\
	\
	state= [num-48]++((lastintervals[0..2])+24);\
	\
	[\cf7 \\statenow\cf0 , state, \cf7 \\prediction\cf0 , rl.a, \cf7 \\target\cf0 , num-48].postln;\
	\
	\cf5 //1 in 20 is a new episode\cf0 \
	if(0.05.coin,\{\
	rl.newepisode(state);\
	\},\{\
	rl.train(state);\
	\});\
	\
	last=now;\
	\});\
	\
\};\
\pard\pardeftab560\ql\qnatural
\cf0 	\
\pard\pardeftab560\li1140\fi-1140\ql\qnatural
\cf0 )\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
}