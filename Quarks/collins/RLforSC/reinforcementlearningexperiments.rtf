{\rtf1\mac\ansicpg10000\cocoartf824\cocoasubrtf410
{\fonttbl\f0\fnil\fcharset77 Monaco;}
{\colortbl;\red255\green255\blue255;\red191\green0\blue0;\red191\green0\blue0;\red0\green0\blue0;
\red0\green0\blue191;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\ql\qnatural\pardirnatural

\f0\fs18 \cf2 //reinforcement learning experiments\cf0 \
\
\cf2 //start one new sarsa process if high level detection of new gross statistical behaviour\cf0 \
\
\cf2 //using SARSA algorithm p146 RL Sutton and Barto 1998\cf0 \
\
\cf2 //central idea is that reward = predictive ability \cf0 \
\
\cf2 //test 1\cf0 \
\
\cf2 //state = input note chroma \cf0 \
\cf2 //action = next predicted chroma\cf0 \
\cf2 //reward =  1 if match, -1 if fail\cf0 \
\cf2 //Q(s,a) is a measure of the expected predictive power of that choice\cf0 \
\
\cf2 //start with a random sequence\cf0 \
\
\cf2 //need fast convergence of prediction if possible! \cf0 \
\cf2 //but this seems to take at least 1000 steps...\cf0 \
\
\
\cf2 //could use n-step rewrds\cf0 \
\cf2 //A sarsa variant then rewards getting more right IN A ROW\cf0 \
\cf2 //this doesn't make much sense for the simple first task below; inevitably we're pushed towards more complicated situations\cf0 \
\cf2 //predict next n as action! \cf0 \
\
\cf2 //simple statistics just aim for a correct choice for the next one\cf0 \
\
\
\cf3 //generalisation performance; how well does the trained algorithm do on a new sequence created from the underlying distribution\cf4 \
\cf0 \
\
\cf5 Post\cf0  << \cf5 Array\cf0 .fill(12*12,\{rrand(0.0,rrand(0.0,1.0))\}) << nl;\
\
\cf5 Post\cf0  << \cf5 Array\cf0 .fill(12,\{\cf5 Array\cf0 .fill(12,\{rrand(0.0,rrand(0.0,1.0))\}).normalizeSum; \}).flatten << nl;\
\
\cf2 //unknown probabiity generator; want to find the unknown Q here\cf0 \
(\
\cf5 var\cf0  data, last, tmp; \
\cf5 var\cf0  p;\
\
p= [ 0.047873594026637, 0.080826749857666, 0.047941249907149, 0.077194165390558, 0.081215439130136, 0.010252900965678, 0.046444197046431, 0.020089243258251, 0.073700618700493, 0.17163013349925, 0.12546371161048, 0.21736799660726, 0.078534462518124, 0.022533184840552, 0.064198699245631, 0.074374510048125, 0.088126562920523, 0.18726247023756, 0.00062892714572889, 0.014489263858497, 0.13721499734884, 0.17094938595627, 0.15133411041267, 0.010353425467481, 0.19111378610518, 0.014393017469096, 0.0037559331238541, 0.019074178375717, 0.16944643368592, 0.02020845034634, 0.0095455981117081, 0.16098607237158, 0.17590293388939, 0.1880851047306, 0.043633839067708, 0.0038546527229134, 0.0081567735414689, 0.22690344224671, 0.067743472620877, 0.31076962725616, 0.0084237407988129, 0.011358108969371, 0.080711913125772, 0.065109429849837, 0.00055617960502401, 0.066195549184565, 0.11475385870385, 0.039317904097556, 0.0060956765907998, 0.023426013859502, 0.046843772017401, 0.067179787769452, 0.034335937191582, 0.10957279228074, 0.029244296399311, 0.22639253418859, 0.14438692079677, 0.22066140123107, 0.00023416852354727, 0.091626699151229, 0.091933253239214, 0.091269157324387, 0.071898821863552, 0.040237280775343, 0.13225676828844, 0.0056224254692286, 0.031726723718983, 0.12915019406708, 0.13641323819981, 0.017130871664528, 0.013707817216658, 0.23865344817278, 0.076312663528366, 0.059262072972401, 0.02598413498885, 0.10410380686335, 0.19017654291831, 0.051217868910339, 0.024773988438023, 0.13696451695503, 0.070062275674588, 0.11358858763476, 0.063837489483962, 0.083716051632018, 0.025471293095253, 0.21257018875625, 0.039804675624999, 0.24661149211191, 0.054061008342468, 0.036708514022697, 0.023420258038583, 0.14986021390175, 0.014181127664185, 0.0099482889621581, 0.023017772199195, 0.16434516728055, 0.082387490785987, 0.039942485347338, 0.22073989653689, 0.017213645836245, 0.11394330239387, 0.1034484413001, 0.064152578780638, 0.0065874717451339, 0.048474126874629, 0.22627620432266, 0.020455668651227, 0.056378687425287, 0.021271296445112, 0.061681184500447, 0.02530307598093, 0.072134796078538, 0.017132372011911, 0.025080142367054, 0.15974665945312, 0.13983710082588, 0.19977101966997, 0.18358013842321, 0.030664291826161, 0.063797922417658, 0.013497094100277, 0.027104913124381, 0.029640856971333, 0.12349064070504, 0.18686140647733, 0.049980116290342, 0.13083701270858, 0.040145869844021, 0.16653194223897, 0.020609360359758, 0.1990519069099, 0.012248880270065, 0.054058801676878, 0.012355204001767, 0.067125199807544, 0.028411207887273, 0.27287333873003, 0.0065108269452922, 0.18297882367653, 0.014016608594546, 0.085673956115894, 0.032365353031109, 0.21630335103269, 0.027327328500458 ]; \cf2 //Array.fill(12,\{Array.fill(12,\{rrand(0.0,rrand(0.0,1.0))\}).normalizeSum; \}).flatten; //will soon be disappointed\cf0 \
\
last=0;\
\
\cf2 //100 samples of this\cf0 \
data=\cf5 Array\cf0 .fill(100,\{tmp= last;  last= p[(tmp*12)..(tmp*12+11)]; last= (0..11).wchoose(last); tmp;\});\
\
\cf5 Post\cf0  << data << nl;\
)\
\
\cf2 //generated by above code with unknown probabilities\cf0 \
[ 0, 11, 0, 11, 4, 5, 1, 4, 9, 2, 9, 7, 3, 3, 7, 5, 1, 10, 8, 9, 8, 9, 1, 8, 0, 4, 8, 0, 0, 3, 9, 7, 1, 2, 8, 4, 9, 5, 0, 1, 5, 11, 4, 9, 3, 3, 3, 3, 6, 4, 5, 4, 7, 11, 8, 4, 1, 5, 0, 1, 3, 10, 8, 2, 4, 4, 9, 9, 7, 3, 6, 0, 2, 7, 5, 7, 10, 8, 6, 0, 3, 7, 3, 11, 8, 0, 11, 8, 4, 3, 7, 3, 7, 10, 9, 6, 5, 8, 2, 9 ]\
\
\
(\
~q3= [ 0.047873594026637, 0.080826749857666, 0.047941249907149, 0.077194165390558, 0.081215439130136, 0.010252900965678, 0.046444197046431, 0.020089243258251, 0.073700618700493, 0.17163013349925, 0.12546371161048, 0.21736799660726, 0.078534462518124, 0.022533184840552, 0.064198699245631, 0.074374510048125, 0.088126562920523, 0.18726247023756, 0.00062892714572889, 0.014489263858497, 0.13721499734884, 0.17094938595627, 0.15133411041267, 0.010353425467481, 0.19111378610518, 0.014393017469096, 0.0037559331238541, 0.019074178375717, 0.16944643368592, 0.02020845034634, 0.0095455981117081, 0.16098607237158, 0.17590293388939, 0.1880851047306, 0.043633839067708, 0.0038546527229134, 0.0081567735414689, 0.22690344224671, 0.067743472620877, 0.31076962725616, 0.0084237407988129, 0.011358108969371, 0.080711913125772, 0.065109429849837, 0.00055617960502401, 0.066195549184565, 0.11475385870385, 0.039317904097556, 0.0060956765907998, 0.023426013859502, 0.046843772017401, 0.067179787769452, 0.034335937191582, 0.10957279228074, 0.029244296399311, 0.22639253418859, 0.14438692079677, 0.22066140123107, 0.00023416852354727, 0.091626699151229, 0.091933253239214, 0.091269157324387, 0.071898821863552, 0.040237280775343, 0.13225676828844, 0.0056224254692286, 0.031726723718983, 0.12915019406708, 0.13641323819981, 0.017130871664528, 0.013707817216658, 0.23865344817278, 0.076312663528366, 0.059262072972401, 0.02598413498885, 0.10410380686335, 0.19017654291831, 0.051217868910339, 0.024773988438023, 0.13696451695503, 0.070062275674588, 0.11358858763476, 0.063837489483962, 0.083716051632018, 0.025471293095253, 0.21257018875625, 0.039804675624999, 0.24661149211191, 0.054061008342468, 0.036708514022697, 0.023420258038583, 0.14986021390175, 0.014181127664185, 0.0099482889621581, 0.023017772199195, 0.16434516728055, 0.082387490785987, 0.039942485347338, 0.22073989653689, 0.017213645836245, 0.11394330239387, 0.1034484413001, 0.064152578780638, 0.0065874717451339, 0.048474126874629, 0.22627620432266, 0.020455668651227, 0.056378687425287, 0.021271296445112, 0.061681184500447, 0.02530307598093, 0.072134796078538, 0.017132372011911, 0.025080142367054, 0.15974665945312, 0.13983710082588, 0.19977101966997, 0.18358013842321, 0.030664291826161, 0.063797922417658, 0.013497094100277, 0.027104913124381, 0.029640856971333, 0.12349064070504, 0.18686140647733, 0.049980116290342, 0.13083701270858, 0.040145869844021, 0.16653194223897, 0.020609360359758, 0.1990519069099, 0.012248880270065, 0.054058801676878, 0.012355204001767, 0.067125199807544, 0.028411207887273, 0.27287333873003, 0.0065108269452922, 0.18297882367653, 0.014016608594546, 0.085673956115894, 0.032365353031109, 0.21630335103269, 0.027327328500458 ]; \
\
~q3.plot;\
)\
\
\
\cf2 //old test data, just randomly produced\cf0 \
[ 7, 9, 8, 5, 5, 6, 5, 0, 1, 7, 6, 11, 5, 4, 2, 2, 3, 0, 4, 10, 2, 4, 7, 11, 6, 2, 6, 3, 3, 3, 7, 7, 5, 5, 7, 1, 6, 6, 8, 1, 11, 8, 7, 9, 8, 4, 11, 3, 4, 0, 6, 5, 3, 8, 11, 11, 10, 1, 8, 6, 3, 3, 7, 6, 1, 3, 3, 10, 6, 1, 4, 9, 6, 7, 6, 6, 2, 5, 1, 11, 9, 4, 6, 2, 4, 11, 1, 5, 9, 2, 3, 5, 7, 4, 4, 0, 5, 8, 4, 6 ]\
\cf2 //Array.rand(100,0,11); //changing over time Prand((0..11),inf).asStream;\cf0 \
\
\
(\
\cf5 var\cf0  data;\
\cf5 var\cf0  q, alpha, eta;\
\cf5 var\cf0  a, s, r, a2, s2;  \cf2 //sarsa variables, a2 = a dash\cf0 \
\cf5 var\cf0  etagreedyfunc;\
\cf5 var\cf0  twelve;\
\cf5 var\cf0  gamma=0.7; \cf2 //reward propagation decay factor, undiscounted?\cf0 \
\cf5 var\cf0  update;\
\
twelve= (0..11);\
\
q= \cf5 Array\cf0 .fill(12*12,\{1\}); \cf2 //will soon be disappointed, starting with too much reward to promote exploration\cf0 \
\
\cf2 //given state, determine action (prediction)\cf0 \
etagreedyfunc=\{\cf5 |state|\cf0 \
	\cf5 var\cf0  tmp, probdistr;\
	\cf5 var\cf0  choice, maxval, maxind; \
	\
	tmp=state*12;\
	\
	tmp= q[tmp..(tmp+11)];\
	\
	choice= if(eta.coin,\{12.rand\},\{\
	\
	\cf2 //this is eta soft \cf0 \
	\cf2 //tmp=tmp.normalizeSum;\cf0 \
	\cf2 //twelve.wchoose(tmp);\cf0 \
	\
	\cf2 //find max index\cf0 \
	\
	maxval=(10000.neg);\
	maxind=0;\
	\
	12.do\{\cf5 |j|\cf0  \cf5 var\cf0  now; now= tmp[j];  if(now>maxval,\{maxval=now; maxind= j\}); \};\
	\
	maxind;\
	\});\
	\
	choice\
\};\
\
alpha=0.1;\
eta= 0.1; \cf2 //0.9;\cf0 \
\
data= [ 0, 11, 0, 11, 4, 5, 1, 4, 9, 2, 9, 7, 3, 3, 7, 5, 1, 10, 8, 9, 8, 9, 1, 8, 0, 4, 8, 0, 0, 3, 9, 7, 1, 2, 8, 4, 9, 5, 0, 1, 5, 11, 4, 9, 3, 3, 3, 3, 6, 4, 5, 4, 7, 11, 8, 4, 1, 5, 0, 1, 3, 10, 8, 2, 4, 4, 9, 9, 7, 3, 6, 0, 2, 7, 5, 7, 10, 8, 6, 0, 3, 7, 3, 11, 8, 0, 11, 8, 4, 3, 7, 3, 7, 10, 9, 6, 5, 8, 2, 9 ]; \
\
\cf2 //(data.size-1)\cf0 \
\
a= etagreedyfunc.value(data[0]);\
\
1000.do(\{\cf5 |i|\cf0 \
	\
	s= data.wrapAt(i);\
	s2=data.wrapAt(i+1);\
	\
	\cf2 //a should actually be a' here if within an episode\cf0 \
	\
	\cf2 //a= etagreedyfunc.value(s);\cf0 \
\
	a2= etagreedyfunc.value(s2);\
	\
	\cf2 //prediction a versus actual observation s2\cf0 \
	r= if(s2==a,\{1\},\{0\});\
	\
	\cf2 //previous value\cf0 \
	update= q[s*12+a];\
	\
	update= update + (alpha*(r + (gamma*(q[s2*12+a2])) - update));\
\
	\cf2 //if(update < 0.001,\{update= 0.001;\});  //safety\cf0 \
\
	q[s*12+a]= update;\
	\
	\cf2 //restricting eta\cf0 \
	\cf2 //if(i%10==0,\{eta= 1000/i;\});\cf0 \
	\cf2 //eta=1/(max(0.1*(i+1),1))\cf0 \
	\cf2 //eta= max(0.001,0.1 - (i/100));\cf0 \
\
	eta= (1000/(i+1));\
	\
	a=a2;\
\});\
\
\
\cf2 //normalise\cf0 \
q = q.clump(12).collect(\{\cf5 |val|\cf0  val.normalizeSum\}).flatten;\
\
~q= q;\
\
\cf5 Post\cf0  << (~q) << nl;\
\
~q.plot;\
\
(~q- ~q3).squared.sum\
\
)\
\
[0,1,2,3,4].clump(12)\
\
\
\
\cf2 //very parameter dependent! \cf0 \
\
\
\cf2 //compare to brute force computation\cf0 \
(\
\cf5 var\cf0  data;\
\cf5 var\cf0  q;\
\cf5 var\cf0  s,s2;\
\
q= \cf5 Array\cf0 .fill(12*12,\{0.0\}); \cf2 //will soon be disappointed\cf0 \
\
data= [ 0, 11, 0, 11, 4, 5, 1, 4, 9, 2, 9, 7, 3, 3, 7, 5, 1, 10, 8, 9, 8, 9, 1, 8, 0, 4, 8, 0, 0, 3, 9, 7, 1, 2, 8, 4, 9, 5, 0, 1, 5, 11, 4, 9, 3, 3, 3, 3, 6, 4, 5, 4, 7, 11, 8, 4, 1, 5, 0, 1, 3, 10, 8, 2, 4, 4, 9, 9, 7, 3, 6, 0, 2, 7, 5, 7, 10, 8, 6, 0, 3, 7, 3, 11, 8, 0, 11, 8, 4, 3, 7, 3, 7, 10, 9, 6, 5, 8, 2, 9 ]; \cf2 //Array.rand(100,0,11); //changing over time Prand((0..11),inf).asStream;\cf0 \
\
(data.size-1).do \{\cf5 |i|\cf0  \
\
	s= data.wrapAt(i);\
	s2=data.wrapAt(i+1);\
	\
	q[s*12+s2] = q[s*12+s2]+1;\
\
\};\
\
q = q.clump(12).collect(\{\cf5 |val|\cf0  val.normalizeSum\}).flatten;\
\
\cf5 Post\cf0  << q << nl;\
\
~q2= q;\
\
~q2.plot\
\
(~q2- ~q3).squared.sum\
\
)\
\
\
\
\
\
\cf2 //now repeat for a probabilistic generator; which method gives better convergence? \cf0 \
\cf2 //should be better generalisation performance from reinforcement learning via TD(0) than Monte Carlo approximation\cf0 \
\
(~q- ~q3).squared.sum\
\
(~q2- ~q3).squared.sum\
\cf2 //monte carlo is not necessarily best fit to true model, as evidenced by choice of parameters here\cf0 \
\
\cf2 //see p144 certainty equivalence estamate; better estimate of future returns\cf0 \
\
\
\
\
\
\
\
\cf2 //sarsa(lambda) p181 in ML book, using eligibility traces- drawback is requiring additional data point for each state, plus iteration over all states each time\cf0 \
\
\
\
(\
\cf5 var\cf0  data;\
\cf5 var\cf0  q, alpha, eta;\
\cf5 var\cf0  a, s, r, a2, s2;  \cf2 //sarsa variables, a2 = a dash\cf0 \
\cf5 var\cf0  etagreedyfunc;\
\cf5 var\cf0  twelve;\
\cf5 var\cf0  gamma=0.9; \cf2 //reward propagation decay factor, undiscounted?\cf0 \
\cf5 var\cf0  update;\
\cf5 var\cf0  e; \
\cf5 var\cf0  lambda;\
\
twelve= (0..11);\
\
q= \cf5 Array\cf0 .fill(12*12,\{1\}); \cf2 //will soon be disappointed, starting with too much reward to promote exploration\cf0 \
\
e= \cf5 Array\cf0 .fill(12*12,\{0\}); \cf2 //eligibility traces\cf0 \
\
lambda= 0.9;\
\
\cf2 //given state, determine action (prediction)\cf0 \
etagreedyfunc=\{\cf5 |state|\cf0 \
	\cf5 var\cf0  tmp, probdistr;\
	\cf5 var\cf0  choice, maxval, maxind; \
	\
	tmp=state*12;\
	\
	tmp= q[tmp..(tmp+11)];\
	\
	choice= if(eta.coin,\{12.rand\},\{\
	\
	\cf2 //this is eta soft \cf0 \
	\cf2 //tmp=tmp.normalizeSum;\cf0 \
	\cf2 //twelve.wchoose(tmp);\cf0 \
	\
	\cf2 //find max index\cf0 \
	\
	maxval=(10000.neg);\
	maxind=0;\
	\
	12.do\{\cf5 |j|\cf0  \cf5 var\cf0  now; now= tmp[j];  if(now>maxval,\{maxval=now; maxind= j\}); \};\
	\
	maxind;\
	\});\
	\
	choice\
\};\
\
alpha=0.1;\
eta= 0.1; \cf2 //0.9;\cf0 \
\
data= [ 0, 11, 0, 11, 4, 5, 1, 4, 9, 2, 9, 7, 3, 3, 7, 5, 1, 10, 8, 9, 8, 9, 1, 8, 0, 4, 8, 0, 0, 3, 9, 7, 1, 2, 8, 4, 9, 5, 0, 1, 5, 11, 4, 9, 3, 3, 3, 3, 6, 4, 5, 4, 7, 11, 8, 4, 1, 5, 0, 1, 3, 10, 8, 2, 4, 4, 9, 9, 7, 3, 6, 0, 2, 7, 5, 7, 10, 8, 6, 0, 3, 7, 3, 11, 8, 0, 11, 8, 4, 3, 7, 3, 7, 10, 9, 6, 5, 8, 2, 9 ]; \
\
\cf2 //(data.size-1)\cf0 \
\
a= etagreedyfunc.value(data[0]);\
\
100.do(\{\cf5 |i|\cf0 \
	\cf5 var\cf0  tmp;\
	\
	s= data.wrapAt(i);\
	s2=data.wrapAt(i+1);\
	\
	\cf2 //a= etagreedyfunc.value(s);\cf0 \
	a2= etagreedyfunc.value(s2);\
	\
	\cf2 //prediction a versus actual observation s2\cf0 \
	r= if(s2==a,\{1\},\{0\});\
	\
	update= q[s*12+a];\
	\
	update= alpha*(r + (gamma*(q[s2*12+a2])) - update);\
\
	e[12*s+a] = e[12*s+a] +1; \cf2 //increment winner\cf0 \
\
	\cf2 //iterate over all 144 states but might only update if e(s,a)>0.0001\cf0 \
	12.do(\{\cf5 |state|\cf0 \
		\
		12.do\{\cf5 |action|\cf0  \
			\cf5 var\cf0  index;\
			\
			index= 12*state+action;\
			tmp= q[index];\
			q[index] = tmp + (update*(e[index]));\
			e[index] =  gamma * lambda * (e[index]);\
			\
		\}; \
		\
	\}); \
\
	a=a2;\
\
	\cf2 //restricting eta\cf0 \
	\cf2 //if(i%10==0,\{eta= 1000/i;\});\cf0 \
	\cf2 //eta=1/(max(0.1*(i+1),1))\cf0 \
	\cf2 //eta= max(0.001,0.1 - (i/1000));\cf0 \
\
	\cf2 //eta= (1000/(i+1));\cf0 \
\});\
\
\
\cf2 //normalise\cf0 \
q = q.clump(12).collect(\{\cf5 |val|\cf0  val.normalizeSum\}).flatten;\
\
~q4= q;\
\
\cf5 Post\cf0  << (~q4) << nl;\
\
~q4.plot;\
\
(~q4- ~q3).squared.sum\
\
)\
\
\
\
\
\
\
\cf2 //want transposition free; predict next interval, not exact pitch\cf0 \
\
\
\
\cf2 //learn over a MIDI File? \cf0 \
\
\cf2 //problem of implementation for last N notes...\cf0 \
\
\
\
\
\
\
\cf2 //rests, timing independently predicted? avoid complexity by sidestepping joint distributions, assume independence\cf0 \
\
}